# Churn Prediction ML Pipeline

A production-grade machine learning pipeline for customer churn prediction using:

- **Kubeflow** for ML pipeline
- **MLflow** for experiment tracking
- **Scikit-learn** for modeling
- **Docker** containers for each stage

---

## ğŸ“¦ Features

- Cleanly structured pipeline: `load â†’ preprocess â†’ train â†’ evaluate â†’ predict`
- Tracked and reproducible ML runs via MLflow
- Modular and maintainable Python package layout
- Configurable through a centralized `.env` file
- Ready for local (Kind) or cloud (Kubernetes) deployment

---

## ğŸš€ Quickstart

### 1. Clone the Repository

### 2. Create a .env file

values should look something like
`RAW_DATA_PATH="path/to/your/data/WA_Fn-UseC_-Telco-Customer-Churn.csv"`

### 3. Create docker images from dockerfiles

I have included a Makefile that creates the docker images from each Dockerfile_* in /dockerfiles. 

To create the Docker images, execute: `make` from project root.

### 4. Consider updating image tags in ml_pipeline() function of pipeline_definition.py

For example, consider this component: `load = load_op(data_path=data_path).set_image('load:latest')`
`set_image()` must feature the correct tag of the docker image you will be using for that pipeline step. You may wish to
tweak these settings depending on your workflow.

---

## ğŸ§  Pipeline Tasks found in /scripts

| Task            | Description                                      |
|-----------------|--------------------------------------------------|
| `load.py`       | Load and persist raw input data as CSV           |
| `preprocess.py` | Create preprocessing pipeline                    |
| `train.py`      | Train LogisticRegression model                   |
| `evaluate.py`   | Evaluate test data + log metrics to Mlfow + plot |
| `deploy.py`     | Serve prediction endpoint via kserve             |
| `predict.py`    | Predict Churn based on cleaned data              |

Each task is independently runnable and integrated into a Kubeflow stage

---

## ğŸ“ Folder Structure

```
ml_pipeline_kubeflow/
â”œâ”€â”€ data/                     # Input/output data
â”‚   â””â”€â”€ WA_Fn-UseC_-Telco-Customer-Churn.csv
â”œâ”€â”€ dockerfiles/
â”‚   â””â”€â”€ Dockerfile_deploy
â”‚   â””â”€â”€ Dockerfile_evaluate
â”‚   â””â”€â”€ Dockerfile_load
â”‚   â””â”€â”€ Dockerfile_predict
â”‚   â””â”€â”€ Dockerfile_train
â”œâ”€â”€ requirements/
â”‚   â””â”€â”€ requirements-deploy.txt
â”‚   â””â”€â”€ requirements-evaluate.txt
â”‚   â””â”€â”€ requirements-load.txt
â”‚   â””â”€â”€ requirements-predict.txt
â”‚   â””â”€â”€ requirements-preprocess.txt
â”‚   â””â”€â”€ requirements-train.txt
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ deploy_utils.py
â”‚   â””â”€â”€ deploy.py
â”‚   â””â”€â”€ evaluate.py
â”‚   â””â”€â”€ load.py
â”‚   â””â”€â”€ predict.py
â”‚   â””â”€â”€ preprocess.py
â”‚   â””â”€â”€ train.py
â”œâ”€â”€ .env                      # Create your own
â”œâ”€â”€ .gitignore
â”œâ”€â”€ LICENSE
â”œâ”€â”€ Makefile
â”œâ”€â”€ pipeline_definition.py    # Where all the things connect
â”œâ”€â”€ README.md
â””â”€â”€ trigger_pipeline.py       # 
```

---

## ğŸ“Š MLflow Tracking

MLflow logs:

- Parameters: `max_iter`
- Metrics: `accuracy`, `precision`, `recall`, `f1`
- Artifacts: model pickle, confusion matrix image

Track at: [http://localhost:5000](http://localhost:5000)

---

## ğŸ§¬ Configuration (`.env`)

```python
RAW_DATA_PATH="/path/to/your/data/WA_Fn-UseC_-Telco-Customer-Churn.csv"
PREDICTION_PATH="/path/to/your/data/predictions.csv"
CLEAN_DATA_PATH="/path/to/your/data/clean_input.csv"
PROCESSSOR_PATH="/path/to/your/data/model_pipeline.pkl"
MODEL_OUTPUT_PATH= "/path/to/your/data/fitted_model_pipeline.pkl"
X_TEST_PATH="/path/to/your/data/X_test.csv"
Y_TEST_PATH="/path/to/your/data/y_test.csv"
CONF_MATRIX_OUTPUT_PATH="/path/to/your/data/conf_matrix.png"
MODEL_NAME="Churn Prediction"
```

---

## Run the API Server

Send a JSON payload such as the following toward  ```/predict```

```JSON
{
  "gender": "Female",
  "SeniorCitizen": 0,
  "Partner": "Yes",
  "Dependents": "No",
  "tenure": 12,
  "PhoneService": "Yes",
  "MultipleLines": "No",
  "InternetService": "Fiber optic",
  "OnlineSecurity": "No",
  "OnlineBackup": "Yes",
  "DeviceProtection": "No",
  "TechSupport": "No",
  "StreamingTV": "Yes",
  "StreamingMovies": "No",
  "Contract": "Month-to-month",
  "PaperlessBilling": "Yes",
  "PaymentMethod": "Electronic check",
  "MonthlyCharges": 75.35,
  "TotalCharges": 850.5
}
```

... and you will receive a response such the following:

```JSON
{
  "prediction": 1,
  "prediction_english": "Churn",
  "churn_probability": 0.6690679352888962
}
```


## âœ… Next Steps

- TODO prove this works on local Kubeflow Pipeline (using Kind)
- Track data versions and schema drift
- Include Infrasture as Code (IaC) tool
- Address scalability concerns

---

## ğŸ§¾ License

MIT License
